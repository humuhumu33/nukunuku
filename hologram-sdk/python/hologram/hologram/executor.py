"""
Executor management with automatic resource cleanup.

Provides Pythonic wrapper around hologram-ffi executor with:
- Context manager for automatic cleanup
- Backend selection (CPU/Metal/CUDA)
- Buffer allocation
"""

from typing import Optional
import numpy as np

from .backend import validate_backend
from .buffer import Buffer

# Import hologram_ffi (generated by UniFFI)
try:
    import hologram_ffi as hg
except ImportError:
    raise ImportError(
        "hologram_ffi not found. Please ensure the hologram-ffi library is built and available. "
        "Run 'cargo build-ffi' in the hologram repository."
    )


class Executor:
    """
    Hologram executor with automatic resource management.

    The executor manages backend selection, buffer allocation, and operation execution.
    Use as a context manager for automatic cleanup.

    Example:
        >>> with Executor(backend='cpu') as exec:
        ...     buf_a = exec.allocate(1024)
        ...     buf_b = exec.allocate(1024)
        ...     # Use buffers...
        # Automatic cleanup

    Example (manual cleanup):
        >>> exec = Executor(backend='cpu')
        >>> buf = exec.allocate(1024)
        >>> # Use buffer...
        >>> exec.cleanup()  # Manual cleanup

    Args:
        backend: Backend type ("cpu", "metal", "cuda", or "auto")
                Default: "auto" (selects best available)

    Raises:
        ValueError: If backend is invalid
        RuntimeError: If backend is not available
    """

    def __init__(self, backend: str = "auto"):
        """
        Create executor with specified backend.

        Args:
            backend: Backend type ("cpu", "metal", "cuda", "auto")

        Raises:
            ValueError: If backend is invalid
            RuntimeError: If backend is not available

        Note:
            Backend selection priority for "auto":
            1. Metal (if on Apple Silicon)
            2. CUDA (if NVIDIA GPU available)
            3. CPU (fallback, always available)
        """
        # Validate and normalize backend
        self._backend_type = validate_backend(backend)

        # Create executor via FFI with appropriate backend
        if self._backend_type == "auto" or backend.lower() == "auto":
            # Use automatic backend selection (Metal → CUDA → CPU)
            self._handle = hg.new_executor_auto()
        else:
            # Use specific backend
            self._handle = hg.new_executor_with_backend(self._backend_type)

        # Check if creation succeeded
        if self._handle == 0:
            raise RuntimeError(
                f"Failed to create executor with backend '{self._backend_type}'. "
                f"Backend may not be available on this system."
            )

        self._freed = False
        self._buffers = []  # Track buffers for cleanup

    @property
    def handle(self) -> int:
        """Get FFI executor handle."""
        return self._handle

    @property
    def backend(self) -> str:
        """Get backend type."""
        return self._backend_type

    def allocate(self, size: int, dtype=np.float32) -> Buffer:
        """
        Allocate a buffer.

        Args:
            size: Number of elements
            dtype: NumPy data type (default: np.float32)

        Returns:
            Buffer object

        Raises:
            RuntimeError: If executor has been freed or allocation fails
            ValueError: If size is invalid
        """
        if self._freed:
            raise RuntimeError("Executor has been freed")

        if size <= 0:
            raise ValueError(f"Buffer size must be positive, got {size}")

        if dtype != np.float32:
            raise NotImplementedError(
                f"Only float32 buffers are currently supported, got {dtype}"
            )

        # Allocate buffer via FFI
        buffer_handle = hg.executor_allocate_buffer(self._handle, size)

        if buffer_handle == 0:
            raise RuntimeError(f"Failed to allocate buffer of size {size}")

        # Create Buffer wrapper
        buffer = Buffer(self, buffer_handle, size, dtype)
        self._buffers.append(buffer)

        return buffer

    def allocate_boundary(
        self,
        class_index: int,
        width: int,
        height: int,
        dtype=np.float32
    ) -> Buffer:
        """
        Allocate a boundary pool buffer (advanced use).

        Boundary pool buffers are L2-resident and map to specific classes.

        Args:
            class_index: Class index [0, 96)
            width: Width dimension
            height: Height dimension
            dtype: NumPy data type (default: np.float32)

        Returns:
            Buffer object

        Raises:
            RuntimeError: If executor has been freed or allocation fails
            ValueError: If parameters are invalid
        """
        if self._freed:
            raise RuntimeError("Executor has been freed")

        if not (0 <= class_index < 96):
            raise ValueError(f"Class index must be in [0, 96), got {class_index}")

        if width <= 0 or height <= 0:
            raise ValueError(f"Width and height must be positive, got {width}x{height}")

        if dtype != np.float32:
            raise NotImplementedError(
                f"Only float32 buffers are currently supported, got {dtype}"
            )

        # Allocate boundary buffer via FFI
        buffer_handle = hg.executor_allocate_boundary_buffer(
            self._handle,
            class_index,
            width,
            height
        )

        if buffer_handle == 0:
            raise RuntimeError(
                f"Failed to allocate boundary buffer "
                f"(class={class_index}, {width}x{height})"
            )

        # Create Buffer wrapper
        size = width * height
        buffer = Buffer(self, buffer_handle, size, dtype)
        self._buffers.append(buffer)

        return buffer

    def cleanup(self) -> None:
        """
        Free executor and all associated buffers.

        Note:
            Normally not needed - use context manager for automatic cleanup.
        """
        if not self._freed:
            # Free all buffers
            for buffer in self._buffers:
                try:
                    if not buffer._freed:
                        buffer.free()
                except:
                    pass  # Ignore errors during cleanup

            self._buffers.clear()

            # Free executor
            hg.executor_cleanup(self._handle)
            self._freed = True

    def __enter__(self):
        """Context manager entry."""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit - automatic cleanup."""
        self.cleanup()
        return False  # Don't suppress exceptions

    def __del__(self):
        """Cleanup on destruction."""
        if not self._freed:
            try:
                self.cleanup()
            except:
                pass  # Ignore errors during cleanup

    def __repr__(self) -> str:
        """String representation."""
        status = "freed" if self._freed else "active"
        return (
            f"Executor(handle={self._handle}, backend='{self._backend_type}', "
            f"buffers={len(self._buffers)}, status={status})"
        )
