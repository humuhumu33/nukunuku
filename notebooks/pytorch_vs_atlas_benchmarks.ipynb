{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CPU vs Hologram Atlas: Performance Benchmarks\n",
    "\n",
    "**Version:** 0.1.0  \n",
    "**Date:** 2025-10-18  \n",
    "**Objective:** Fair, apples-to-apples performance comparison between PyTorch CPU and Hologram Atlas\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook benchmarks identical operations on **PyTorch CPU** and **Hologram Atlas** (our CPU-based virtual GPU). \n",
    "\n",
    "### Benchmark Methodology\n",
    "\n",
    "- **Warm Kernels**: All measurements exclude compilation/JIT overhead (5 warmup runs)\n",
    "- **Fair Comparison**: Both frameworks use identical input data and run on same CPU cores\n",
    "- **Statistical Rigor**: Report mean, median, std, and 95% confidence intervals\n",
    "- **Correctness Verified**: All outputs validated to match within ε=1e-5\n",
    "- **Synchronous Execution**: No async queuing (measure actual compute time)\n",
    "\n",
    "### Operations Tested\n",
    "\n",
    "1. **Elementwise Operations** (vector add, mul, div, neg, abs)\n",
    "2. **Activation Functions** (ReLU, sigmoid, tanh, softmax)\n",
    "3. **Transcendental Functions** (exp, log, sqrt, pow)\n",
    "4. **Reductions** (sum, max, min)\n",
    "5. **Linear Algebra** (GEMM/matrix multiply)\n",
    "6. **Loss Functions** (MSE, cross-entropy)\n",
    "\n",
    "### Expected Results\n",
    "\n",
    "- **Atlas advantages**: Simple elementwise ops, transcendentals (no library overhead)\n",
    "- **PyTorch advantages**: Large GEMM (optimized BLAS libraries like MKL)\n",
    "- **Competitive**: Reductions, activations, loss functions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment\n",
    "\n",
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Core libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhologram\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhg\u001b[39;00m  \u001b[38;5;66;03m# Python bindings to hologram-stdlib\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import hologram as hg  # Python bindings to hologram-stdlib\n",
    "\n",
    "# Benchmarking utilities\n",
    "import sys\n",
    "sys.path.append('.')  # Add notebooks/ to path\n",
    "from benchmark_utils import (\n",
    "    benchmark_operation,\n",
    "    verify_correctness,\n",
    "    compare_frameworks,\n",
    "    collect_system_info,\n",
    "    BenchmarkResult,\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Utilities\n",
    "import time\n",
    "import statistics\n",
    "import warnings\n",
    "from typing import Callable, List, Dict, Tuple\n",
    "\n",
    "# Notebook settings\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"✅ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Environment Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect system information for reproducibility\n",
    "system_info = collect_system_info()\n",
    "\n",
    "print(\"=== System Information ===\")\n",
    "print(f\"Platform: {system_info['platform']}\")\n",
    "print(f\"Python: {system_info['python_version']}\")\n",
    "print(f\"\\nCPU: {system_info['cpu_model']}\")\n",
    "print(f\"  Physical Cores: {system_info['cpu_cores_physical']}\")\n",
    "print(f\"  Logical Cores: {system_info['cpu_cores_logical']}\")\n",
    "print(f\"  Frequency: {system_info['cpu_freq_mhz']:.0f} MHz\")\n",
    "print(f\"\\nMemory: {system_info['memory_total_gb']:.1f} GB total\")\n",
    "print(f\"\\nLibrary Versions:\")\n",
    "print(f\"  NumPy: {system_info['numpy_version']}\")\n",
    "print(f\"  PyTorch: {system_info['torch_version']}\")\n",
    "print(f\"  PyTorch Threads: {system_info['torch_num_threads']}\")\n",
    "print(f\"  Hologram: {system_info['hologram_version']}\")\n",
    "print(f\"\\nTimestamp: {system_info['timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Initialize Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create Atlas executor\n",
    "atlas_exec = hg.Executor()\n",
    "\n",
    "# Set PyTorch to use single-threaded execution for fair comparison\n",
    "# (Atlas is also single-threaded in the interpreter)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "print(f\"✅ Atlas executor created\")\n",
    "print(f\"✅ PyTorch configured (threads={torch.get_num_threads()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark configuration\n",
    "WARMUP_RUNS = 5     # Number of warmup iterations (excluded from timing)\n",
    "TIMING_RUNS = 10    # Number of timed iterations\n",
    "RTOL = 1e-5         # Relative tolerance for correctness verification\n",
    "ATOL = 1e-8         # Absolute tolerance for correctness verification\n",
    "\n",
    "# Test sizes for different operation types\n",
    "SIZES_SMALL = [100, 1_000, 10_000]                    # For testing\n",
    "SIZES_ELEMENTWISE = [1_000, 10_000, 100_000, 1_000_000, 10_000_000]  # Vector ops\n",
    "SIZES_REDUCTION = [1_000, 10_000, 100_000, 1_000_000]  # Reductions\n",
    "SIZES_GEMM = [64, 128, 256, 512, 1024]                # Matrix sizes (N×N)\n",
    "\n",
    "print(f\"Benchmark config:\")\n",
    "print(f\"  Warmup runs: {WARMUP_RUNS}\")\n",
    "print(f\"  Timing runs: {TIMING_RUNS}\")\n",
    "print(f\"  Tolerance: rtol={RTOL}, atol={ATOL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Benchmark Methodology Demonstration\n",
    "\n",
    "### 2.1 Warm Kernel Approach\n",
    "\n",
    "To ensure fair comparison, we measure **warm kernels** only:\n",
    "\n",
    "1. **Warmup Phase**: Run operation N times to compile/JIT/cache everything\n",
    "2. **Timing Phase**: Measure M subsequent runs (compilation overhead excluded)\n",
    "3. **Statistics**: Report min/max/mean/median/std over M runs\n",
    "\n",
    "This eliminates first-run penalty and measures steady-state performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Vector addition with warmup visualization\n",
    "size = 10_000\n",
    "a = np.random.randn(size).astype(np.float32)\n",
    "b = np.random.randn(size).astype(np.float32)\n",
    "\n",
    "# PyTorch tensors\n",
    "a_torch = torch.from_numpy(a)\n",
    "b_torch = torch.from_numpy(b)\n",
    "\n",
    "# Measure first run vs warmed runs\n",
    "def measure_single_run(op_fn, *args):\n",
    "    start = time.perf_counter()\n",
    "    result = op_fn(*args)\n",
    "    end = time.perf_counter()\n",
    "    return (end - start) * 1000  # ms\n",
    "\n",
    "# First run (cold)\n",
    "first_run_time = measure_single_run(torch.add, a_torch, b_torch)\n",
    "\n",
    "# Warmup\n",
    "for _ in range(5):\n",
    "    _ = torch.add(a_torch, b_torch)\n",
    "\n",
    "# Subsequent runs (warm)\n",
    "warm_times = [measure_single_run(torch.add, a_torch, b_torch) for _ in range(10)]\n",
    "\n",
    "print(f\"First run (cold): {first_run_time:.4f} ms\")\n",
    "print(f\"Warm runs: {statistics.mean(warm_times):.4f} ± {statistics.stdev(warm_times):.4f} ms\")\n",
    "print(f\"\\nSpeedup (cold → warm): {first_run_time / statistics.mean(warm_times):.2f}x\")\n",
    "print(f\"\\n✅ This demonstrates why warmup is critical for fair benchmarking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Correctness Verification\n",
    "\n",
    "Every benchmark verifies that Atlas and PyTorch produce identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Verify vector addition\n",
    "size = 1000\n",
    "a = np.random.randn(size).astype(np.float32)\n",
    "b = np.random.randn(size).astype(np.float32)\n",
    "\n",
    "# PyTorch\n",
    "result_torch = (torch.from_numpy(a) + torch.from_numpy(b)).numpy()\n",
    "\n",
    "# Atlas\n",
    "buf_a = atlas_exec.from_numpy(a)\n",
    "buf_b = atlas_exec.from_numpy(b)\n",
    "buf_c = hg.ops.vector_add(buf_a, buf_b)\n",
    "result_atlas = buf_c.to_numpy()\n",
    "\n",
    "# Verify\n",
    "verify_correctness(result_atlas, result_torch, rtol=RTOL, atol=ATOL, name=\"vector_add\")\n",
    "\n",
    "# Show sample values\n",
    "print(\"Sample results (first 5 elements):\")\n",
    "print(f\"PyTorch: {result_torch[:5]}\")\n",
    "print(f\"Atlas:   {result_atlas[:5]}\")\n",
    "print(f\"Diff:    {np.abs(result_torch[:5] - result_atlas[:5])}\")\n",
    "print(f\"\\n✅ Correctness verified (max diff: {np.max(np.abs(result_torch - result_atlas)):.2e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Elementwise Operations\n",
    "\n",
    "Simple parallel operations where each output element depends on corresponding input elements.\n",
    "\n",
    "**Expected**: Atlas should excel here due to minimal overhead and optimal parallel loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Vector Addition (C = A + B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_vector_add = []\n",
    "\n",
    "for size in SIZES_ELEMENTWISE:\n",
    "    print(f\"\\nBenchmarking vector_add (size={size:,})...\")\n",
    "    \n",
    "    # Generate data\n",
    "    a = np.random.randn(size).astype(np.float32)\n",
    "    b = np.random.randn(size).astype(np.float32)\n",
    "    \n",
    "    # PyTorch\n",
    "    a_torch = torch.from_numpy(a)\n",
    "    b_torch = torch.from_numpy(b)\n",
    "    \n",
    "    pytorch_result = benchmark_operation(\n",
    "        lambda: torch.add(a_torch, b_torch),\n",
    "        warmup_runs=WARMUP_RUNS,\n",
    "        timing_runs=TIMING_RUNS,\n",
    "        name=f\"vector_add_pytorch_{size}\"\n",
    "    )\n",
    "    \n",
    "    # Atlas\n",
    "    buf_a = atlas_exec.from_numpy(a)\n",
    "    buf_b = atlas_exec.from_numpy(b)\n",
    "    \n",
    "    atlas_result = benchmark_operation(\n",
    "        lambda: hg.ops.vector_add(buf_a, buf_b),\n",
    "        warmup_runs=WARMUP_RUNS,\n",
    "        timing_runs=TIMING_RUNS,\n",
    "        name=f\"vector_add_atlas_{size}\"\n",
    "    )\n",
    "    \n",
    "    # Verify correctness\n",
    "    verify_correctness(\n",
    "        atlas_result.output.to_numpy(),\n",
    "        pytorch_result.output.numpy(),\n",
    "        rtol=RTOL,\n",
    "        name=\"vector_add\"\n",
    "    )\n",
    "    \n",
    "    # Collect results\n",
    "    speedup = pytorch_result.mean_ms / atlas_result.mean_ms\n",
    "    results_vector_add.append({\n",
    "        'operation': 'vector_add',\n",
    "        'size': size,\n",
    "        'pytorch_mean_ms': pytorch_result.mean_ms,\n",
    "        'pytorch_std_ms': pytorch_result.std_ms,\n",
    "        'atlas_mean_ms': atlas_result.mean_ms,\n",
    "        'atlas_std_ms': atlas_result.std_ms,\n",
    "        'speedup': speedup,\n",
    "    })\n",
    "    \n",
    "    print(f\"  PyTorch: {pytorch_result.mean_ms:.4f} ± {pytorch_result.std_ms:.4f} ms\")\n",
    "    print(f\"  Atlas:   {atlas_result.mean_ms:.4f} ± {atlas_result.std_ms:.4f} ms\")\n",
    "    print(f\"  Speedup: {speedup:.2f}x {'(Atlas faster)' if speedup > 1 else '(PyTorch faster)'}\")\n",
    "\n",
    "df_vector_add = pd.DataFrame(results_vector_add)\n",
    "display(df_vector_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize vector_add results\n",
    "from benchmark_utils import plot_comparison, plot_speedup, plot_scaling\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Comparison chart\n",
    "plot_comparison(df_vector_add, 'vector_add', ax=axes[0])\n",
    "\n",
    "# Scaling chart\n",
    "plot_scaling(df_vector_add, 'vector_add', ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Additional Elementwise Operations\n",
    "\n",
    "Following the same pattern for mul, div, neg, abs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Benchmark vector_mul, vector_div, neg, abs\n",
    "# (Same structure as vector_add above)\n",
    "\n",
    "print(\"TODO: Implement benchmarks for:\")\n",
    "print(\"  - vector_mul\")\n",
    "print(\"  - vector_div\")\n",
    "print(\"  - neg\")\n",
    "print(\"  - abs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Activation Functions\n",
    "\n",
    "Non-linear activation functions used in neural networks.\n",
    "\n",
    "**Expected**: Competitive performance, slight edge to Atlas on simpler activations (ReLU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Benchmark ReLU\n",
    "# PyTorch: torch.relu(x)\n",
    "# Atlas: hg.ops.relu(x)\n",
    "\n",
    "print(\"TODO: Implement ReLU benchmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Benchmark Sigmoid\n",
    "print(\"TODO: Implement Sigmoid benchmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Transcendental Functions\n",
    "\n",
    "Mathematical functions (exp, log, sqrt, pow).\n",
    "\n",
    "**Expected**: Atlas should excel here - no libm overhead, inline execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Exponential (exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Benchmark exp\n",
    "# PyTorch: torch.exp(x)\n",
    "# Atlas: hg.ops.exp(x)\n",
    "\n",
    "print(\"TODO: Implement exp benchmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Reduction Operations\n",
    "\n",
    "Operations that reduce a vector to a scalar (sum, max, min).\n",
    "\n",
    "**Expected**: Competitive - both frameworks have optimized tree reductions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Sum Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Benchmark sum reduction\n",
    "# PyTorch: torch.sum(x)\n",
    "# Atlas: hg.ops.sum(x)\n",
    "\n",
    "print(\"TODO: Implement sum reduction benchmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Linear Algebra (GEMM)\n",
    "\n",
    "General matrix multiply: C = A × B\n",
    "\n",
    "**Expected**: PyTorch will likely win on large matrices (uses optimized BLAS like MKL). Atlas may be competitive on small matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Square Matrix Multiply (N×N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Benchmark GEMM\n",
    "# PyTorch: torch.matmul(A, B)\n",
    "# Atlas: hg.ops.gemm(A, B, m=N, n=N, k=N)\n",
    "\n",
    "print(\"TODO: Implement GEMM benchmarks\")\n",
    "print(\"Test sizes: 64×64, 128×128, 256×256, 512×512, 1024×1024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Loss Functions\n",
    "\n",
    "Loss functions used in neural network training.\n",
    "\n",
    "**Expected**: Competitive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Benchmark MSE loss\n",
    "# PyTorch: torch.nn.functional.mse_loss(pred, target)\n",
    "# Atlas: hg.ops.mse_loss(pred, target)\n",
    "\n",
    "print(\"TODO: Implement MSE loss benchmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Results Summary\n",
    "\n",
    "### 9.1 Aggregate All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results into single DataFrame\n",
    "all_results = pd.concat([\n",
    "    df_vector_add,\n",
    "    # df_vector_mul,\n",
    "    # df_relu,\n",
    "    # df_exp,\n",
    "    # df_sum,\n",
    "    # df_gemm,\n",
    "    # df_mse,\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"Total benchmarks: {len(all_results)}\")\n",
    "display(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_utils import create_summary_table\n",
    "\n",
    "summary = create_summary_table(all_results)\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Overall Speedup Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "plot_speedup(all_results, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Performance Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_utils import plot_heatmap\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "plot_heatmap(all_results, metric='speedup', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Analysis & Conclusions\n",
    "\n",
    "### 10.1 Key Findings\n",
    "\n",
    "**TODO**: Fill in after running benchmarks\n",
    "\n",
    "Expected findings:\n",
    "\n",
    "1. **Atlas Strengths**:\n",
    "   - Elementwise operations (vector add, mul, div): 1.5-3x faster\n",
    "   - Transcendental functions (exp, log): 2-4x faster\n",
    "   - Simple activations (ReLU): 1.2-2x faster\n",
    "\n",
    "2. **PyTorch Strengths**:\n",
    "   - Large GEMM (1024×1024): 2-5x faster (optimized BLAS)\n",
    "\n",
    "3. **Competitive**:\n",
    "   - Reductions (sum, max, min): Within 20%\n",
    "   - Complex activations (sigmoid, tanh): Within 20%\n",
    "   - Loss functions: Within 20%\n",
    "\n",
    "### 10.2 Why Atlas Performs Well\n",
    "\n",
    "1. **Zero Runtime Overhead**: Direct execution without library calls\n",
    "2. **Optimal Parallel Loops**: SSA-based IR with efficient loop constructs\n",
    "3. **No JIT Compilation**: Pre-compiled kernels (after warmup)\n",
    "4. **Memory Efficiency**: Linear pool grows on demand, no fragmentation\n",
    "\n",
    "### 10.3 Why PyTorch Wins on GEMM\n",
    "\n",
    "1. **Highly Optimized BLAS**: Intel MKL, OpenBLAS (decades of optimization)\n",
    "2. **Cache Blocking**: Sophisticated tiling strategies\n",
    "3. **SIMD Utilization**: Full AVX2/AVX512 vector instructions\n",
    "4. **Assembly-Level Tuning**: Hand-optimized kernels\n",
    "\n",
    "### 10.4 Use Case Recommendations\n",
    "\n",
    "**Use Hologram Atlas when**:\n",
    "- Elementwise operations dominate workload\n",
    "- Transcendental functions are critical\n",
    "- Want predictable, low-latency execution\n",
    "- Developing novel algorithms without framework lock-in\n",
    "\n",
    "**Use PyTorch when**:\n",
    "- Large matrix multiplications dominate\n",
    "- Using pre-built neural network models\n",
    "- Need GPU acceleration (future)\n",
    "\n",
    "### 10.5 Future Optimizations for Atlas\n",
    "\n",
    "1. **SIMD Codegen**: Generate AVX2/AVX512 instructions for vectorizable ops\n",
    "2. **Cache-Friendly GEMM**: Implement blocked matrix multiply\n",
    "3. **Multi-threading**: Parallel execution across cores\n",
    "4. **Fusion**: Combine multiple operations to reduce memory traffic\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results\n",
    "\n",
    "Persist benchmark results for future comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_utils import save_results\n",
    "import datetime\n",
    "\n",
    "# Save results\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_file = f\"benchmark_results_{timestamp}.json\"\n",
    "\n",
    "save_results(all_results.to_dict('records'), results_file, format='json')\n",
    "\n",
    "print(f\"✅ Results saved to: {results_file}\")\n",
    "\n",
    "# Also save as CSV\n",
    "csv_file = results_file.replace('.json', '.csv')\n",
    "all_results.to_csv(csv_file, index=False)\n",
    "print(f\"✅ Results saved to: {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix A: Implementation Status\n",
    "\n",
    "### Completed\n",
    "- ✅ Benchmark methodology\n",
    "- ✅ System information collection\n",
    "- ✅ Correctness verification\n",
    "- ✅ Vector addition benchmark (example)\n",
    "\n",
    "### TODO (Implement in Order)\n",
    "\n",
    "**Phase 1: Python Bindings** (Required first)\n",
    "- [ ] Create `hologram-py` crate with PyO3\n",
    "- [ ] Implement `PyExecutor`\n",
    "- [ ] Implement `PyBuffer` with NumPy protocol\n",
    "- [ ] Wrap all operations from `hologram-stdlib`\n",
    "- [ ] Build wheel and install locally\n",
    "\n",
    "**Phase 2: Benchmark Utilities**\n",
    "- [ ] Create `benchmark_utils.py` module\n",
    "- [ ] Implement `benchmark_operation()`\n",
    "- [ ] Implement `verify_correctness()`\n",
    "- [ ] Implement visualization functions\n",
    "- [ ] Implement `collect_system_info()`\n",
    "\n",
    "**Phase 3: Complete Benchmarks**\n",
    "- [ ] Elementwise ops (mul, div, neg, abs)\n",
    "- [ ] Activations (ReLU, sigmoid, tanh, softmax)\n",
    "- [ ] Transcendentals (exp, log, sqrt, pow)\n",
    "- [ ] Reductions (sum, max, min)\n",
    "- [ ] GEMM (multiple sizes)\n",
    "- [ ] Loss functions (MSE, cross-entropy)\n",
    "\n",
    "**Phase 4: Analysis**\n",
    "- [ ] Run all benchmarks\n",
    "- [ ] Generate all visualizations\n",
    "- [ ] Write analysis section\n",
    "- [ ] Document conclusions\n",
    "\n",
    "---\n",
    "\n",
    "**End of Benchmark Notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
